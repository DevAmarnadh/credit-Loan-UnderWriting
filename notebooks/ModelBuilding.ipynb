{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "cc9c29f7-6d91-40d7-bb15-c194693d4c8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7723577235772358\n",
      "Confusion Matrix:\n",
      "[[18 25]\n",
      " [ 3 77]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           N       0.86      0.42      0.56        43\n",
      "           Y       0.75      0.96      0.85        80\n",
      "\n",
      "    accuracy                           0.77       123\n",
      "   macro avg       0.81      0.69      0.70       123\n",
      "weighted avg       0.79      0.77      0.75       123\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['../model/label_encoders.pkl']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys\n",
    "sys.path.append('../src')  # Ensure src directory is added to the system path\n",
    "\n",
    "# Import custom preprocessing functions\n",
    "from data_preprocessing import load_data, handle_missing_values\n",
    "from feature_engineering import encode_categorical_variables, add_total_income_feature\n",
    "from model_training import train_model\n",
    "from predictions import make_predictions, save_predictions\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "import joblib\n",
    "\n",
    "# Load the preprocessed data\n",
    "train_data = pd.read_csv('../data/train_cleaned.csv')\n",
    "test_data = pd.read_csv('../data/test_cleaned.csv')\n",
    "\n",
    "# Combine train and test data for consistent encoding\n",
    "combined_data = pd.concat([train_data, test_data], axis=0, ignore_index=True)\n",
    "\n",
    "# Feature Engineering: Add Total Income feature\n",
    "combined_data = add_total_income_feature(combined_data)\n",
    "\n",
    "# Encode categorical variables using LabelEncoder\n",
    "combined_data, label_encoders = encode_categorical_variables(combined_data)\n",
    "\n",
    "# Further processing, model training, and prediction code follows...\n",
    "\n",
    "# Split the combined data back into train and test sets\n",
    "train_data = combined_data.iloc[:train_data.shape[0], :]\n",
    "test_data = combined_data.iloc[train_data.shape[0]:, :]\n",
    "\n",
    "# Separate into features (X) and target variable (y)\n",
    "X = train_data.drop(columns=['Loan_ID', 'Loan_Status'])  # Exclude non-numeric and target columns\n",
    "y = train_data['Loan_Status']\n",
    "\n",
    "# Split the data into training and validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Feature Scaling (only scale numeric columns)\n",
    "numeric_cols = X.select_dtypes(include=['int64', 'float64']).columns\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Handle 'Dependents' column properly to avoid SettingWithCopyWarning\n",
    "X_train['Dependents'] = X_train['Dependents'].replace('3+', 3).astype(int)\n",
    "X_val['Dependents'] = X_val['Dependents'].replace('3+', 3).astype(int)\n",
    "test_data.loc[:, 'Dependents'] = test_data['Dependents'].replace('3+', 3).astype(int)\n",
    "\n",
    "# Scale numeric columns\n",
    "X_train_scaled = X_train.copy()\n",
    "X_val_scaled = X_val.copy()\n",
    "test_data_scaled = test_data.copy()\n",
    "\n",
    "X_train_scaled[numeric_cols] = scaler.fit_transform(X_train[numeric_cols])\n",
    "X_val_scaled[numeric_cols] = scaler.transform(X_val[numeric_cols])\n",
    "test_data_scaled[numeric_cols] = scaler.transform(test_data[numeric_cols])\n",
    "\n",
    "# Model Building: Train the Random Forest Classifier\n",
    "model = RandomForestClassifier(random_state=42)\n",
    "model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Evaluate the model\n",
    "y_pred = model.predict(X_val_scaled)\n",
    "accuracy = accuracy_score(y_val, y_pred)\n",
    "confusion = confusion_matrix(y_val, y_pred)\n",
    "classification_rep = classification_report(y_val, y_pred)\n",
    "\n",
    "# Print evaluation metrics\n",
    "print(f'Accuracy: {accuracy}')\n",
    "print(f'Confusion Matrix:\\n{confusion}')\n",
    "print(f'Classification Report:\\n{classification_rep}')\n",
    "\n",
    "# Save the trained model\n",
    "joblib.dump(model, '../model/random_forest_model.pkl')\n",
    "\n",
    "\n",
    "\n",
    "# Make predictions on the test set\n",
    "test_predictions = make_predictions(model, test_data_scaled.drop(columns=['Loan_ID', 'Loan_Status']))\n",
    "\n",
    "# Prepare the submission file\n",
    "save_predictions(test_predictions, test_data, filename='../data/loan_predictions.csv')\n",
    "\n",
    "# At the end of encode_categorical_variables function\n",
    "joblib.dump(label_encoders, '../model/label_encoders.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2c7d6e80-0ac2-4b21-add7-ce8b740c11cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved successfully at ../model/random_forest_model.pkl\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "import os\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Assuming `model` is your trained model\n",
    "model = RandomForestClassifier(random_state=42)\n",
    "model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Save the trained model\n",
    "model_path = '../model/random_forest_model.pkl'\n",
    "joblib.dump(model, model_path)\n",
    "\n",
    "# Verify if the model is saved correctly\n",
    "if not os.path.exists(model_path):\n",
    "    raise Exception(f\"Model not saved at {model_path}\")\n",
    "else:\n",
    "    print(f\"Model saved successfully at {model_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fd779c47-9d01-4851-b5cf-b9790b1f2d2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved successfully at ../model/random_forest_model.pkl\n",
      "Label encoders saved successfully at ../model/label_encoders.pkl\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "import os\n",
    "\n",
    "# Save the trained model\n",
    "model_path = '../model/random_forest_model.pkl'\n",
    "joblib.dump(model, model_path)\n",
    "\n",
    "# Save the label encoders\n",
    "encoders_path = '../model/label_encoders.pkl'\n",
    "joblib.dump(label_encoders, encoders_path)\n",
    "\n",
    "# Verify if the files are saved correctly\n",
    "if not os.path.exists(model_path):\n",
    "    raise Exception(f\"Model not saved at {model_path}\")\n",
    "else:\n",
    "    print(f\"Model saved successfully at {model_path}\")\n",
    "\n",
    "if not os.path.exists(encoders_path):\n",
    "    raise Exception(f\"Label encoders not saved at {encoders_path}\")\n",
    "else:\n",
    "    print(f\"Label encoders saved successfully at {encoders_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9f36221b-c29c-42d1-a778-379ed63e5047",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model file size: 1556201 bytes\n",
      "Encoders file size: 1737 bytes\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "model_path = '../model/random_forest_model.pkl'\n",
    "encoders_path = '../model/label_encoders.pkl'\n",
    "\n",
    "print(f\"Model file size: {os.path.getsize(model_path)} bytes\")\n",
    "print(f\"Encoders file size: {os.path.getsize(encoders_path)} bytes\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3de690bd-e7c2-4ecf-b8c3-1a8346f7b278",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
